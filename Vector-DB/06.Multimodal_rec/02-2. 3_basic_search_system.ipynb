{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. VectorDB 구축\n",
    "\n",
    "#### Local DB 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(\"../data/imaterialist-fashion-2020-fgvc7/attribute_specific.csv\")\n",
    "df = pd.read_csv(\"../data/imaterialist-fashion-2020-fgvc7/clothes_final2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 97924 fashion-fine-tuned CLIP embeddings from img_embeddings_fashion_fine_tuned.json\n"
     ]
    }
   ],
   "source": [
    "data_read_f = list()\n",
    "\n",
    "with open(\"../data/imaterialist-fashion-2020-fgvc7/upsert_vectors_fashion_fine_tuned.json\", 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        data_read_f.append(data)\n",
    "\n",
    "print(f\"Successfully read {len(data_read_f)} fashion-fine-tuned CLIP embeddings from img_embeddings_fashion_fine_tuned.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vdb_id'] = df['ImageId'].astype(str) + \"_\" + df['entity_id'].astype(str)\n",
    "df.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_df_f = pd.DataFrame(data_read_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_0</td>\n",
       "      <td>[0.18243342638015747, 0.7801597714424133, -0.0...</td>\n",
       "      <td>{'indices': [1035, 2053, 2171, 2240, 2315, 233...</td>\n",
       "      <td>{'img_path': 'imaterialist-fashion-2020-fgvc7/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_1</td>\n",
       "      <td>[0.046928003430366516, 0.9497855305671692, -1....</td>\n",
       "      <td>{'indices': [1035, 2053, 2058, 2098, 2171, 218...</td>\n",
       "      <td>{'img_path': 'imaterialist-fashion-2020-fgvc7/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  \\\n",
       "0  00000663ed1ff0c4e0132b9b9ac53f6e_0   \n",
       "1  00000663ed1ff0c4e0132b9b9ac53f6e_1   \n",
       "\n",
       "                                              values  \\\n",
       "0  [0.18243342638015747, 0.7801597714424133, -0.0...   \n",
       "1  [0.046928003430366516, 0.9497855305671692, -1....   \n",
       "\n",
       "                                       sparse_values  \\\n",
       "0  {'indices': [1035, 2053, 2171, 2240, 2315, 233...   \n",
       "1  {'indices': [1035, 2053, 2058, 2098, 2171, 218...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'img_path': 'imaterialist-fashion-2020-fgvc7/...  \n",
       "1  {'img_path': 'imaterialist-fashion-2020-fgvc7/...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsert_df_f.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.merge(df, upsert_df_f, left_on='vdb_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.to_csv(\"local_db.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>AttributesIds</th>\n",
       "      <th>second_AttributesIds</th>\n",
       "      <th>bbox</th>\n",
       "      <th>bbox_big</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>name</th>\n",
       "      <th>supercategory</th>\n",
       "      <th>AttributesNames</th>\n",
       "      <th>second_AttributesNames</th>\n",
       "      <th>vdb_id</th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e</td>\n",
       "      <td>6068157 7 6073371 20 6078584 34 6083797 48 608...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>6</td>\n",
       "      <td>115,136,143,154,230,295,316,317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1163, 3923, 2839, 5212]</td>\n",
       "      <td>[1122, 3891, 2880, 5214]</td>\n",
       "      <td>1758</td>\n",
       "      <td>1323</td>\n",
       "      <td>2325834</td>\n",
       "      <td>pants</td>\n",
       "      <td>lowerbody</td>\n",
       "      <td>symmetrical, regular (fit), low waist, maxi (l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_0</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_0</td>\n",
       "      <td>[0.18243342638015747, 0.7801597714424133, -0.0...</td>\n",
       "      <td>{'indices': [1035, 2053, 2171, 2240, 2315, 233...</td>\n",
       "      <td>{'img_path': 'imaterialist-fashion-2020-fgvc7/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e</td>\n",
       "      <td>6323163 11 6328356 32 6333549 53 6338742 75 63...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>0</td>\n",
       "      <td>115,136,142,146,225,295,316,317</td>\n",
       "      <td>163</td>\n",
       "      <td>[1212, 1371, 2394, 3978]</td>\n",
       "      <td>[1183, 1306, 2423, 4043]</td>\n",
       "      <td>1240</td>\n",
       "      <td>2737</td>\n",
       "      <td>3393880</td>\n",
       "      <td>shirt, blouse</td>\n",
       "      <td>upperbody</td>\n",
       "      <td>symmetrical, regular (fit), normal waist, abov...</td>\n",
       "      <td>shirt (collar)</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_1</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_1</td>\n",
       "      <td>[0.046928003430366516, 0.9497855305671692, -1....</td>\n",
       "      <td>{'indices': [1035, 2053, 2058, 2098, 2171, 218...</td>\n",
       "      <td>{'img_path': 'imaterialist-fashion-2020-fgvc7/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_id                           ImageId  \\\n",
       "0          0  00000663ed1ff0c4e0132b9b9ac53f6e   \n",
       "1          1  00000663ed1ff0c4e0132b9b9ac53f6e   \n",
       "\n",
       "                                       EncodedPixels  Height  Width  ClassId  \\\n",
       "0  6068157 7 6073371 20 6078584 34 6083797 48 608...    5214   3676        6   \n",
       "1  6323163 11 6328356 32 6333549 53 6338742 75 63...    5214   3676        0   \n",
       "\n",
       "                     AttributesIds second_AttributesIds  \\\n",
       "0  115,136,143,154,230,295,316,317                  NaN   \n",
       "1  115,136,142,146,225,295,316,317                  163   \n",
       "\n",
       "                       bbox                  bbox_big  width  height     area  \\\n",
       "0  [1163, 3923, 2839, 5212]  [1122, 3891, 2880, 5214]   1758    1323  2325834   \n",
       "1  [1212, 1371, 2394, 3978]  [1183, 1306, 2423, 4043]   1240    2737  3393880   \n",
       "\n",
       "            name supercategory  \\\n",
       "0          pants     lowerbody   \n",
       "1  shirt, blouse     upperbody   \n",
       "\n",
       "                                     AttributesNames second_AttributesNames  \\\n",
       "0  symmetrical, regular (fit), low waist, maxi (l...                    NaN   \n",
       "1  symmetrical, regular (fit), normal waist, abov...         shirt (collar)   \n",
       "\n",
       "                               vdb_id                                  id  \\\n",
       "0  00000663ed1ff0c4e0132b9b9ac53f6e_0  00000663ed1ff0c4e0132b9b9ac53f6e_0   \n",
       "1  00000663ed1ff0c4e0132b9b9ac53f6e_1  00000663ed1ff0c4e0132b9b9ac53f6e_1   \n",
       "\n",
       "                                              values  \\\n",
       "0  [0.18243342638015747, 0.7801597714424133, -0.0...   \n",
       "1  [0.046928003430366516, 0.9497855305671692, -1....   \n",
       "\n",
       "                                       sparse_values  \\\n",
       "0  {'indices': [1035, 2053, 2171, 2240, 2315, 233...   \n",
       "1  {'indices': [1035, 2053, 2058, 2098, 2171, 218...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'img_path': 'imaterialist-fashion-2020-fgvc7/...  \n",
       "1  {'img_path': 'imaterialist-fashion-2020-fgvc7/...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = d['metadata'].values\n",
    "names = d['name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_new = list()\n",
    "\n",
    "for n,m in zip(names, metadata):\n",
    "    m['category'] = n\n",
    "    metadata_new.append(m)\n",
    "\n",
    "d['metadata'] = metadata_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': 'imaterialist-fashion-2020-fgvc7/cropped_images/ffffbf7014a9e408bfbb81a75bc70638_97923.jpg',\n",
       " 'category': 'dress'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>AttributesIds</th>\n",
       "      <th>second_AttributesIds</th>\n",
       "      <th>bbox</th>\n",
       "      <th>bbox_big</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>name</th>\n",
       "      <th>supercategory</th>\n",
       "      <th>AttributesNames</th>\n",
       "      <th>second_AttributesNames</th>\n",
       "      <th>vdb_id</th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e</td>\n",
       "      <td>6068157 7 6073371 20 6078584 34 6083797 48 608...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>6</td>\n",
       "      <td>115,136,143,154,230,295,316,317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1163, 3923, 2839, 5212]</td>\n",
       "      <td>[1122, 3891, 2880, 5214]</td>\n",
       "      <td>1758</td>\n",
       "      <td>1323</td>\n",
       "      <td>2325834</td>\n",
       "      <td>pants</td>\n",
       "      <td>lowerbody</td>\n",
       "      <td>symmetrical, regular (fit), low waist, maxi (l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_0</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_0</td>\n",
       "      <td>[0.18243342638015747, 0.7801597714424133, -0.0...</td>\n",
       "      <td>{'indices': [1035, 2053, 2171, 2240, 2315, 233...</td>\n",
       "      <td>{'img_path': 'imaterialist-fashion-2020-fgvc7/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e</td>\n",
       "      <td>6323163 11 6328356 32 6333549 53 6338742 75 63...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>0</td>\n",
       "      <td>115,136,142,146,225,295,316,317</td>\n",
       "      <td>163</td>\n",
       "      <td>[1212, 1371, 2394, 3978]</td>\n",
       "      <td>[1183, 1306, 2423, 4043]</td>\n",
       "      <td>1240</td>\n",
       "      <td>2737</td>\n",
       "      <td>3393880</td>\n",
       "      <td>shirt, blouse</td>\n",
       "      <td>upperbody</td>\n",
       "      <td>symmetrical, regular (fit), normal waist, abov...</td>\n",
       "      <td>shirt (collar)</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_1</td>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e_1</td>\n",
       "      <td>[0.046928003430366516, 0.9497855305671692, -1....</td>\n",
       "      <td>{'indices': [1035, 2053, 2058, 2098, 2171, 218...</td>\n",
       "      <td>{'img_path': 'imaterialist-fashion-2020-fgvc7/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_id                           ImageId  \\\n",
       "0          0  00000663ed1ff0c4e0132b9b9ac53f6e   \n",
       "1          1  00000663ed1ff0c4e0132b9b9ac53f6e   \n",
       "\n",
       "                                       EncodedPixels  Height  Width  ClassId  \\\n",
       "0  6068157 7 6073371 20 6078584 34 6083797 48 608...    5214   3676        6   \n",
       "1  6323163 11 6328356 32 6333549 53 6338742 75 63...    5214   3676        0   \n",
       "\n",
       "                     AttributesIds second_AttributesIds  \\\n",
       "0  115,136,143,154,230,295,316,317                  NaN   \n",
       "1  115,136,142,146,225,295,316,317                  163   \n",
       "\n",
       "                       bbox                  bbox_big  width  height     area  \\\n",
       "0  [1163, 3923, 2839, 5212]  [1122, 3891, 2880, 5214]   1758    1323  2325834   \n",
       "1  [1212, 1371, 2394, 3978]  [1183, 1306, 2423, 4043]   1240    2737  3393880   \n",
       "\n",
       "            name supercategory  \\\n",
       "0          pants     lowerbody   \n",
       "1  shirt, blouse     upperbody   \n",
       "\n",
       "                                     AttributesNames second_AttributesNames  \\\n",
       "0  symmetrical, regular (fit), low waist, maxi (l...                    NaN   \n",
       "1  symmetrical, regular (fit), normal waist, abov...         shirt (collar)   \n",
       "\n",
       "                               vdb_id                                  id  \\\n",
       "0  00000663ed1ff0c4e0132b9b9ac53f6e_0  00000663ed1ff0c4e0132b9b9ac53f6e_0   \n",
       "1  00000663ed1ff0c4e0132b9b9ac53f6e_1  00000663ed1ff0c4e0132b9b9ac53f6e_1   \n",
       "\n",
       "                                              values  \\\n",
       "0  [0.18243342638015747, 0.7801597714424133, -0.0...   \n",
       "1  [0.046928003430366516, 0.9497855305671692, -1....   \n",
       "\n",
       "                                       sparse_values  \\\n",
       "0  {'indices': [1035, 2053, 2171, 2240, 2315, 233...   \n",
       "1  {'indices': [1035, 2053, 2058, 2098, 2171, 218...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'img_path': 'imaterialist-fashion-2020-fgvc7/...  \n",
       "1  {'img_path': 'imaterialist-fashion-2020-fgvc7/...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PineconeDB에 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pinecone upsert 형식에 맞게 내용을 변환\n",
    "    - 각 카테고리별로 batch에 맞게 upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 512,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## pineconeDB에 upsert!!\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "# index 개수 확인\n",
    "# index_list = pc.list_indexes().indexes\n",
    "\n",
    "# index description\n",
    "index = pc.Index(\"fastcampus\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Max size for an upsert request is 2MB. Recommended upsert limit is 100 vectors per request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee8530f91d04266bdab00fb35447225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 카테고리별로 나눠서 저장함\n",
    "# 이는 이후 index를 개별로 저장하기 위함\n",
    "\n",
    "# upsert!!\n",
    "def create_batches(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "df_categories = dict()\n",
    "\n",
    "for cat in tqdm(d['name'].unique()):\n",
    "    part_df = d.loc[d['name']==cat]\n",
    "    part_upserts = part_df[['id', 'values', 'sparse_values', 'metadata']].to_dict('records')\n",
    "    # 100개 단위로 upsert\n",
    "    df_categories[cat] = list(create_batches(part_upserts, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pants', 'shirt, blouse', 'jacket', 'top, t-shirt, sweatshirt', 'dress', 'shoe', 'glasses', 'skirt', 'bag, wallet', 'belt', 'headband, head covering, hair accessory', 'sock', 'hat', 'watch', 'glove', 'tights, stockings', 'sweater', 'tie', 'shorts', 'scarf', 'coat', 'vest', 'umbrella', 'cardigan', 'cape', 'jumpsuit', 'leg warmer'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_categories['shoe'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsert 형식\n",
    "\n",
    "```json\n",
    "{\"id\" : \"0838a48a7b0bfa789a5181ab0e8f4ee2_3040\", # 이미지 파일 이름 + entity ID\n",
    " \"values\" : [-0.08405803143978119, -0.7088879346847534, ...], # CLIP embeddings\n",
    " \"sparse_values\" : {\n",
    "    \"indices\" : [1045, 1062, ...], # non-zero index\n",
    "    \"values\" : [1.3038887977600098, 0.304147332906723, ...] # non-zero values\n",
    "    },\n",
    "\"metadata\" : {\n",
    "    # 이미지 파일 path\n",
    "    \"img_path\": \"../data/imaterialist-fashion-2020-fgvc7/cropped_images/0838a48a7b0bfa789a5181ab0e8f4ee2_3040.jpg\",\n",
    "    \"category\": \"coat\"\n",
    "} \n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # upsert to 'fastcampus' index\n",
    "# for cat, batches in df_categories.items():\n",
    "#     print(cat)\n",
    "#     for batch in tqdm(batches):\n",
    "#         index.upsert(vectors=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 카테고리별로 개별 index에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text to image search\n",
    "\n",
    "- CLIP embedding을 활용\n",
    "    - text와 image를 한 vector space에 함께 표현되어 있음\n",
    "    - 또한, fashion dataset에 맞도록 fine-tune되어, 일반 plain CLIP보다 현재 use case에 적합\n",
    "    - Fine-tune된 데이터 역시 옷의 다양한 attribute을 바탕으로 트레이닝 [Fine-tune 훈련 데이터](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-022-23052-9/MediaObjects/41598_2022_23052_Fig3_HTML.png?as=webp, \"Fine-tune 훈련 데이터\")\n",
    "\n",
    "(출처 : Contrastive language and vision learning of general fashion concepts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from image_utils import fetch_clip, draw_images\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_utils import gen_sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splade.splade.models.transformer_rep import Splade\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "splade_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "# splade = 'naver/splade-v3'\n",
    "splade_model = Splade(splade_model_id, agg='max')\n",
    "splade_model.to('cpu')  # move to GPU if possible\n",
    "splade_model.eval()\n",
    "\n",
    "splade_tokenizer = AutoTokenizer.from_pretrained(splade_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, processor, tokenizer = fetch_clip(model_name=\"patrickjohncyh/fashion-clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_text_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors = \"pt\", padding=True)\n",
    "    text_embeddings = model.get_text_features(**inputs)\n",
    "    # convert the embeddings to numpy array\n",
    "    embedding_as_np = text_embeddings.cpu().detach().numpy()\n",
    "    return embedding_as_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Green dress with blue dots, long sleeve\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=5,\n",
    "    filter={\"category\": {\"$eq\": \"dress\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"nike\"\n",
    "\n",
    "# vans, nike, addidas\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=5,\n",
    "    filter={\"category\": {\"$eq\": \"shoe\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"street fashion\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Punk Fashion\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Bohemian Fashion\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"flower patterns, short sleeve\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점\n",
    "    - 유명 브랜드, 성별, 옷의 종류, 색갈 등의 카테고리를 매뉴얼하게 정하지 않아도 input으로 정해줄 수 있다\n",
    "\n",
    "- 한계점\n",
    "    - attribute들의 단순 결합이기 때문에 옷의 부위 별 특징을 인식하지 못 함\n",
    "        - 예) blue dots이라고 명시했지만, 파란색 드레스가 유사도에 표현됨\n",
    "    - 스트릿, 보헤미안 패션 등 추상적인 단어들은 다양한 옷들의 조합임\n",
    "    (CLIP은 <옷의 특징>-<옷의 사진> pair를 활용하여 학습. 따라서 \"스트릿패션\"과 같이 패션의 한 카테고리와 매칭이 되지 않는다.)\n",
    "\n",
    "- 극복 방안\n",
    "    - Sparse vector를 활용하여 옷의 특징에 weight를 더 주는 search\n",
    "    - 옷의 특징이 아닌, 보다 추상적인 텍스트가 들어오는 경우, database 전체를 대상으로 search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Image to image search\n",
    "\n",
    "- CLIP embedding을 활용\n",
    "    - text와 image를 한 vector space에 함께 표현되어 있지만 Image-to-Image 유사도 측정도이 가능함\n",
    "    - 또한, fashion dataset에 맞도록 fine-tune되어, 일반 plain CLIP보다 현재 use case에 적합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import extract_img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"../data/imaterialist-fashion-2020-fgvc7/test_images/test_image2.jpg\")\n",
    "\n",
    "img_emb = extract_img_features(image, processor, model).tolist()\n",
    "\n",
    "result = index.query(\n",
    "    vector=img_emb[0],\n",
    "    top_k=5,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"../data/imaterialist-fashion-2020-fgvc7/test_images/test_image.jpg\")\n",
    "\n",
    "img_emb = extract_img_features(image, processor, model).tolist()\n",
    "\n",
    "result = index.query(\n",
    "    vector=img_emb[0],\n",
    "    top_k=5,\n",
    "    filter={\"category\": {\"$eq\": \"shirt, blouse\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한계점\n",
    "    - 이미지에는 옷의 색, 사람들의 포즈, 빛 등 다양한 요소들이 모두 포함되어 있기 때문에 옷의 특징들만 선별하여 서치를 진행할 수 없음\n",
    "    - 즉, 옷의 디테일을 간과할 가능성이 높음\n",
    "- 극복 방안\n",
    "    - 이미지로부터 옷의 특징을 텍스트 형식으로 추출, dense vector 또는 sparse vector로 변환하여 서치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hybrid search (Dense & sparse vector search)\n",
    "\n",
    "- splade를 활용하여 각 파트별 특징까지 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splade.splade.models.transformer_rep import Splade\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "sparse_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "# splade = 'naver/splade-v3'\n",
    "sparse_model = Splade(sparse_model_id, agg='max')\n",
    "sparse_model.to('cpu')  # move to GPU if possible\n",
    "sparse_model.eval()\n",
    "\n",
    "splade_tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v-neck\n",
    "input_text = \"orange party dress with long sleeve, v neck\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "# sparse = gen_sparse_vector(input_text, splade_model, splade_tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=5,\n",
    "    filter={\"category\": {\"$eq\": \"dress\"}},\n",
    "    # sparse_vector=sparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v-neck\n",
    "input_text = \"orange party dress with long sleeve, v neck\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "sparse = gen_sparse_vector(input_text, splade_model, splade_tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=5,\n",
    "    filter={\"category\": {\"$eq\": \"dress\"}},\n",
    "    sparse_vector=sparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vdb_id</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>AttributesNames</th>\n",
       "      <th>second_AttributesNames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9336</th>\n",
       "      <td>1874544733f9b11f236154d77faf87c9_9336</td>\n",
       "      <td>1874544733f9b11f236154d77faf87c9</td>\n",
       "      <td>bodycon (dress), symmetrical, pencil, normal w...</td>\n",
       "      <td>boat (neck), elbow-length, set-in sleeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59947</th>\n",
       "      <td>9cf94dbf0a5f4bf24233e3eb5bba71fb_59947</td>\n",
       "      <td>9cf94dbf0a5f4bf24233e3eb5bba71fb</td>\n",
       "      <td>tunic (dress), symmetrical, a-line, normal wai...</td>\n",
       "      <td>v-neck, set-in sleeve, wrist-length, dropped-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78568</th>\n",
       "      <td>cde8b89c650ec766fa35bdf588e64d4e_78568</td>\n",
       "      <td>cde8b89c650ec766fa35bdf588e64d4e</td>\n",
       "      <td>tunic (dress), symmetrical, circle, high waist...</td>\n",
       "      <td>bishop (sleeve), boat (neck), wrist-length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79807</th>\n",
       "      <td>d121674ebd3ecfd561821fa9f83ac831_79807</td>\n",
       "      <td>d121674ebd3ecfd561821fa9f83ac831</td>\n",
       "      <td>tunic (dress), a-line, mini (length), no openi...</td>\n",
       "      <td>v-neck, set-in sleeve, wrist-length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94373</th>\n",
       "      <td>f701653e4cac2fc6e5a3fb9baa3591e1_94373</td>\n",
       "      <td>f701653e4cac2fc6e5a3fb9baa3591e1</td>\n",
       "      <td>tea (dress), symmetrical, a-line, high waist, ...</td>\n",
       "      <td>bishop (sleeve), v-neck, wrist-length</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       vdb_id  \\\n",
       "9336    1874544733f9b11f236154d77faf87c9_9336   \n",
       "59947  9cf94dbf0a5f4bf24233e3eb5bba71fb_59947   \n",
       "78568  cde8b89c650ec766fa35bdf588e64d4e_78568   \n",
       "79807  d121674ebd3ecfd561821fa9f83ac831_79807   \n",
       "94373  f701653e4cac2fc6e5a3fb9baa3591e1_94373   \n",
       "\n",
       "                                ImageId  \\\n",
       "9336   1874544733f9b11f236154d77faf87c9   \n",
       "59947  9cf94dbf0a5f4bf24233e3eb5bba71fb   \n",
       "78568  cde8b89c650ec766fa35bdf588e64d4e   \n",
       "79807  d121674ebd3ecfd561821fa9f83ac831   \n",
       "94373  f701653e4cac2fc6e5a3fb9baa3591e1   \n",
       "\n",
       "                                         AttributesNames  \\\n",
       "9336   bodycon (dress), symmetrical, pencil, normal w...   \n",
       "59947  tunic (dress), symmetrical, a-line, normal wai...   \n",
       "78568  tunic (dress), symmetrical, circle, high waist...   \n",
       "79807  tunic (dress), a-line, mini (length), no openi...   \n",
       "94373  tea (dress), symmetrical, a-line, high waist, ...   \n",
       "\n",
       "                                  second_AttributesNames  \n",
       "9336            boat (neck), elbow-length, set-in sleeve  \n",
       "59947  v-neck, set-in sleeve, wrist-length, dropped-s...  \n",
       "78568         bishop (sleeve), boat (neck), wrist-length  \n",
       "79807                v-neck, set-in sleeve, wrist-length  \n",
       "94373              bishop (sleeve), v-neck, wrist-length  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "# draw_images([Image.open(i) for i in paths])\n",
    "\n",
    "[i['id'] for i in result.matches]\n",
    "\n",
    "df.loc[df['vdb_id'].isin([i['id'] for i in result.matches]), ['vdb_id', 'ImageId', 'AttributesNames', 'second_AttributesNames']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f701653e4cac2fc6e5a3fb9baa3591e1_94373',\n",
       " 'd121674ebd3ecfd561821fa9f83ac831_79807',\n",
       " '1874544733f9b11f236154d77faf87c9_9336',\n",
       " '9cf94dbf0a5f4bf24233e3eb5bba71fb_59947',\n",
       " 'cde8b89c650ec766fa35bdf588e64d4e_78568']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i['id'] for i in result.matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패션 스타일 관련 text field가 없기 때문에, sparse vector를 활용하더라도 큰 퍼포먼스 향상을 기대하기 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Punk Fashion\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "# sparse = gen_sparse_vector(input_text, splade_model, splade_tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    # sparse_vector=sparse,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Punk Fashion\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "sparse = gen_sparse_vector(input_text, splade_model, splade_tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    sparse_vector=sparse,\n",
    "    filter={\"category\": {\"$eq\": \"top, t-shirt, sweatshirt\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 활용할 수 있는 attribute의 종류\n",
    "```python\n",
    "list_of_attributes = ['main_category', 'silhouette', 'silhouette_fit', 'waistline', 'length',\n",
    "       'collar_type', 'neckline_type', 'sleeve_type', 'pocket_type',\n",
    "       'opening_type', 'non-textile material type', 'leather',\n",
    "       'textile finishing, manufacturing techniques', 'textile pattern']\n",
    "```\n",
    "<br>\n",
    "\n",
    "- attribute으로 표현할 수 있는 document의 포맷\n",
    "\n",
    "```json\n",
    "silhouette_name : symmetrical,\n",
    "collar_type_name : shirt (collar),\n",
    "opening_type_name : single breasted,\n",
    "non-textile material type_name : no non-textile material,\n",
    "textile finishing, manufacturing techniques_name : no special manufacturing technique,\n",
    "textile pattern_name : plain (pattern)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"test_images/test_image3.png\")\n",
    "\n",
    "img_emb = extract_img_features(image, processor, model).tolist()\n",
    "\n",
    "result = index.query(\n",
    "    vector=img_emb,\n",
    "    top_k=5,  # how many results to return\n",
    "    filter={\"category\": {\"$eq\": \"jacket\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = ['../data/'+i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"test_images/test_image3.png\")\n",
    "\n",
    "img_emb = extract_img_features(image, processor, model).tolist()\n",
    "\n",
    "sparse_vector = gen_sparse_vector(\"suede jacket\", sparse_model, splade_tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=img_emb,\n",
    "    sparse_vector=sparse_vector,\n",
    "    top_k=5,  # how many results to return\n",
    "    filter={\"category\": {\"$eq\": \"jacket\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = [i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
