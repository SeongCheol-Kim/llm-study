{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OyiNEwNq-zC"
   },
   "source": [
    "# Example 1: PDF 테이블 정보에 대한 Recursive Retrieval 전략\n",
    "- 다수의 CSV 테이블 대상으로 검색 chunk와 답변 생성 chunk 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DJlOhrfy3WQW"
   },
   "outputs": [],
   "source": [
    "# 윈도우에서 사용시 Ghostscript 추가 설치 필요\n",
    "# https://ghostscript.com/releases/gsdnld.html\n",
    "import camelot\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import PandasQueryEngine\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oVP_VqtK3pFv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9VxZeTuM4H5O"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# 추후 사용할 llm, 임베딩 모델 클래스 정의\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wxyb04mj4J4V"
   },
   "outputs": [],
   "source": [
    "# PDF link\n",
    "# https://en.wikipedia.org/wiki/The_World%27s_Billionaires\n",
    "\n",
    "# 파싱할 파일 경로 설정\n",
    "file_path = \"../data/The_World's_Billionaires.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cONRosvi4NmW"
   },
   "outputs": [],
   "source": [
    "# PDF파서 정의\n",
    "reader = PyMuPDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n6u6nrur4Ojl"
   },
   "outputs": [],
   "source": [
    "# 업로드된 경로에서 로딩스테이지 진행한 후 다큐먼트 단위로 저장\n",
    "docs = reader.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Mm5zH5vFMTyb"
   },
   "outputs": [],
   "source": [
    "# # 다큐먼트 정보 확인\n",
    "# # 읽기 부적합하게 파싱된 것 확인\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Mmu4gEzsv2-E"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "#노드변환 및 파싱\n",
    "doc_nodes = Settings.node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vhjFY59tv2wG"
   },
   "outputs": [],
   "source": [
    "# text만 query하는 engine 정의\n",
    "vector_index0 = VectorStoreIndex(doc_nodes)\n",
    "vector_query_engine0 = vector_index0.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4a9gx3kKv2m7"
   },
   "outputs": [],
   "source": [
    "response = vector_query_engine0.query(\n",
    "    \"How many billionaires were there in 2009?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lQL2n1DQwihe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 답변 생성시 사용된 node 확인\n",
    "# print(response.source_nodes[0].node.get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-a7oeurlwyBI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 793 billionaires were listed in 2009.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eu-457Wow5si"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$195 billion\n"
     ]
    }
   ],
   "source": [
    "# naive-RAG의 잘못된 retrieve 예시\n",
    "response = vector_query_engine0.query(\n",
    "    \"What's the net worth of the second richest billionaire in 2023?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nVr2YU4ZxJod"
   },
   "outputs": [],
   "source": [
    "# # 답변 생성시 사용된 node 확인\n",
    "# print(response.source_nodes[0].node.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIwAKSUyxUi9"
   },
   "source": [
    "- 기본적인 PDF파싱모듈로는 테이블 등 Text-Only 가 아닌 문서에 대한 정보 해석력이 떨어지는 것을 확인\n",
    "- Table정보를 따로 추출하여 답하는 방식 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UZqmYOK34nzI"
   },
   "outputs": [],
   "source": [
    "# pdf의 테이블파싱\n",
    "def get_tables(path: str, pages: List[int]):\n",
    "    table_dfs = []\n",
    "    for page in pages:\n",
    "        table_list = camelot.read_pdf(path, pages=str(page))\n",
    "        for table in table_list:\n",
    "            table_df = table.df\n",
    "            table_df = (\n",
    "                table_df.rename(columns=table_df.iloc[0])\n",
    "                .drop(table_df.index[0])\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            table_dfs.append(table_df)\n",
    "    return table_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AjNpfgAu4qe3"
   },
   "outputs": [],
   "source": [
    "table_dfs = get_tables(file_path, pages=[3,4,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kBfOwQpFtsRv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3, 4, 24페이지에서 파싱된 테이블 개수확인\n",
    "len(table_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6n1RZ9eR4r4u"
   },
   "outputs": [],
   "source": [
    "# #파싱 결과 확인\n",
    "# table_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-Yu4kglM6Fbo"
   },
   "outputs": [],
   "source": [
    "# #파싱 결과 확인\n",
    "# table_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "w5T7CKfbslDi"
   },
   "outputs": [],
   "source": [
    "# #파싱 결과 확인\n",
    "# table_dfs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 테이블별로 답해주는 담당 라마인덱스 쿼리엔진 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtU0KdVGueIP"
   },
   "source": [
    "테이블이 수천 수만개일 때, 모든 유저 쿼리에 대해 수만개의 테이블을 매번 조회하는 것은 실용성 없는 Naive한 접근방식(자원은 무한하지 않다).\n",
    "\n",
    "그렇기 때문에,\n",
    "1. 사용자의 질문과 관련된 테이블을 먼저 찾고\n",
    "2. 찾은 테이블을 기준으로 사용자의 질문에 답할 수 있는 정보를 발췌하여 답변 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "StvfC4Zf6Zcx"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# pandas df 전용 query 엔진\n",
    "df_query_engines = [\n",
    "    PandasQueryEngine(table_df, llm=llm) for table_df in table_dfs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "J7Ycg0GC6nUW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$195 billion\n"
     ]
    }
   ],
   "source": [
    "# 상응하는 테이블 지정해서 답변 요구\n",
    "response = df_query_engines[0].query(\n",
    "    \"What's the net worth of the second richest billionaire in 2024?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Pa-Y88s2uGCD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$180 billion\n"
     ]
    }
   ],
   "source": [
    "# 상응하는 테이블 지정해서 답변 요구\n",
    "response = df_query_engines[1].query(\n",
    "    \"What's the net worth of the second richest billionaire in 2023?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ebG04J6b682-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793\n"
     ]
    }
   ],
   "source": [
    "response = df_query_engines[3].query(\n",
    "    \"How many billionaires were there in 2009?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTO4d7YBuPed"
   },
   "source": [
    "질문별로 담당하는 쿼리엔진을 부여하는 것으로 heuristic하게 서칭 스페이스를 줄이고 시작할 수 있는 것 확인  \n",
    "but, 질문별 담당 쿼리엔진 선택 자동화 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IV3WkyE87Piq"
   },
   "outputs": [],
   "source": [
    "# 쿼리엔진별 요약문 생성\n",
    "summaries = [\n",
    "    (\n",
    "        \"This node provides information about the world's richest billionaires\"\n",
    "        \" in 2024\"\n",
    "    ),\n",
    "    (\n",
    "        \"This node provides information about the world's richest billionaires\"\n",
    "        \" in 2023\"\n",
    "    ),\n",
    "    (\n",
    "        \"This node provides information about the world's richest billionaires\"\n",
    "        \" in 2022\"\n",
    "    ),\n",
    "    # (\n",
    "    #     \"This node provides information about the world's richest billionaires\"\n",
    "    #     \" in 2020\"\n",
    "    # ),\n",
    "    (\n",
    "        \"This node provides information on the number of billionaires and\"\n",
    "        \" their combined net worth from 2000 to 2023.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "#생성된 요약문 별 노드단위 생성\n",
    "df_nodes = [\n",
    "    IndexNode(text=summary, index_id=f\"pandas{idx}\")\n",
    "    for idx, summary in enumerate(summaries)\n",
    "]\n",
    "\n",
    "#요약노드 <-> 쿼리엔진 매핑\n",
    "df_id_query_engine_mapping = {\n",
    "    f\"pandas{idx}\": df_query_engine\n",
    "    for idx, df_query_engine in enumerate(df_query_engines)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "W9r6sgnC-aCz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexNode(id_='782cbc03-7015-43c7-bfc2-6b1c6e156e33', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"This node provides information about the world's richest billionaires in 2024\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='pandas0', obj=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#생성된 노드 확인\n",
    "df_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DkDkhtbT7at5"
   },
   "outputs": [],
   "source": [
    "# 상위레벨 벡터스토어인덱스 정의\n",
    "# 최상위 task는 유저의 질문에 잘 답할 수 있는 node를 찾는 것이 됨\n",
    "vector_index = VectorStoreIndex(df_nodes)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=1) # 답을 가장 잘 할 수 있는 노드를 찾아야해서 top_K가 1이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "I8GJ2buh7seZ"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever},\n",
    "    query_engine_dict=df_id_query_engine_mapping,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "\n",
    "# 최종 query 엔진\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    recursive_retriever, response_synthesizer=response_synthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mwXbaAE68DSg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: What's the net worth of the second richest billionaire in 2023?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: pandas1\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id pandas1: What's the net worth of the second richest billionaire in 2023?\n",
      "\u001b[0m\u001b[1;3;32mGot response: $180 billion\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What's the net worth of the second richest billionaire in 2023?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ro7CvuDL8Eu8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Query: What's the net worth of the second richest billionaire in 2023?\\nResponse: $180 billion\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].node.get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "e6RdeFFD8Wyp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$180 billion'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0TlIRMVL8b2k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: How many billionaires were there in 2009?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: pandas3\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id pandas3: How many billionaires were there in 2009?\n",
      "\u001b[0m\u001b[1;3;32mGot response: 15    793\n",
      "Name: Number of billionaires, dtype: object\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many billionaires were there in 2009?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5qqxJrrh8rrR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There were 793 billionaires in 2009.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEc4dK7yyRhH"
   },
   "source": [
    "- 서머리 텍스트로 recursive retriever 모듈로 하여금 우리가 찾고자 하는 문서를 자동으로 판별해서 해당 쿼리엔진을 기반으로만 답하게 하는 것이 가능한 것 확인\n",
    "  \n",
    "- Searching 공간을 최적화하는 것이 RAG 성능에 중요한 영향"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone DB에 있는 데이터와 연계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "c-Re4gNbIJAS"
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import re\n",
    "import os\n",
    "\n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "EnZO7bmRH6rU"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# 데이터 로드\n",
    "dataset = load_dataset(\"lcw99/wikipedia-korean-20221001\", split='train[:1000]')\n",
    "data = dataset.to_pandas()[['id', 'text', 'title']].drop_duplicates(subset='text', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xg-f0vAaKAGE"
   },
   "outputs": [],
   "source": [
    "def clean_up_text(content: str) -> str:\n",
    "    content = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', content)\n",
    "\n",
    "    content = re.sub(r'\\\\n|  —|——————————|—————————|—————|\\\\u[\\dA-Fa-f]{4}|\\uf075|\\uf0b7', \"\", content)\n",
    "\n",
    "    content = re.sub(r'(\\w)\\s*-\\s*(\\w)', r'\\1-\\2', content)\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xg-f0vAaKAGE"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "documents = [Document(\n",
    "    text=clean_up_text(row['text']),\n",
    "    doc_id=row['id'],\n",
    "    extra_info={'title': row['title']}\n",
    ") for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "TmqgL4APKucH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>제임스 얼 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39대...</td>\n",
       "      <td>지미 카터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>수학(數學, , 줄여서 math)은 수, 양, 구조, 공간, 변화 등의 개념을 다루...</td>\n",
       "      <td>수학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>수학에서 상수란 그 값이 변하지 않는 불변량으로, 변수의 반대말이다. 물리 상수와는...</td>\n",
       "      <td>수학 상수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>문학(文學, )은 언어를 예술적 표현의 제재로 삼아 새로운 의미를 창출하여, 인간과...</td>\n",
       "      <td>문학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 하였다. 협정...</td>\n",
       "      <td>나라 목록</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  title\n",
       "0   5  제임스 얼 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39대...  지미 카터\n",
       "1   9  수학(數學, , 줄여서 math)은 수, 양, 구조, 공간, 변화 등의 개념을 다루...     수학\n",
       "2  10  수학에서 상수란 그 값이 변하지 않는 불변량으로, 변수의 반대말이다. 물리 상수와는...  수학 상수\n",
       "3  19  문학(文學, )은 언어를 예술적 표현의 제재로 삼아 새로운 의미를 창출하여, 인간과...     문학\n",
       "4  20  이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 하였다. 협정...  나라 목록"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "FIh8SR6aUiGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# 파인콘 인덱스 생성\n",
    "from time import sleep\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "index_name=\"quickstart\"\n",
    "\n",
    "if index_name in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "   name=index_name,\n",
    "   dimension=1536,\n",
    "   metric=\"dotproduct\",\n",
    "   spec=ServerlessSpec(\n",
    "       cloud='aws',\n",
    "       region='us-east-1'\n",
    "   )\n",
    ")\n",
    "\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    sleep(1)\n",
    "index = pc.Index(index_name)\n",
    "sleep(1)\n",
    "index_stats = index.describe_index_stats()\n",
    "print(index_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "PYOE8Y_pUnRe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15204\\3549792048.py:11: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c936176ac157461289ed76d0915e5444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a890d470d16b4ea1b96b91b61ccecfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad344026a404ce0b5e55acc8fb7d1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/1474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, ServiceContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "vector_store = PineconeVectorStore(pinecone_index=index)\n",
    "# 벡터스토어 인덱스에 들어가는 스토리지 컴포넌트 정의\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store\n",
    ")\n",
    "embed_model = OpenAIEmbedding(model='text-embedding-ada-002', embed_batch_size=100)\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "HcKWmkoBW1jJ"
   },
   "outputs": [],
   "source": [
    "# Query 엔진 가변화 with OpenAIAgent(function call)\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "agents = {}\n",
    "\n",
    "for title in `.title:\n",
    "    vector_query_engine = index.as_query_engine(vector_store_kwargs={\"filter\": {\"title\": title}})\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description=(\n",
    "                    f\"{title}에 대해서 물어볼 때 사용\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    function_llm = OpenAI(model=\"gpt-4-turbo-preview\", temperature=0)\n",
    "    agent = OpenAIAgent.from_tools(\n",
    "        query_engine_tools,\n",
    "        llm=function_llm,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    agents[title] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "8Pn874D7WN61"
   },
   "outputs": [],
   "source": [
    "# #생성된 에이전트 확인\n",
    "# agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "DEwegUz3hWcR"
   },
   "outputs": [],
   "source": [
    "# 에이전트 선택을 위한 에이전트 summary\n",
    "nodes = []\n",
    "for title in data.title:\n",
    "    doc_summary = (\n",
    "        f\"이것은 {title}과 관련된 내용이 있습니다. \"\n",
    "        f\"{title}과 관련된 내용을 확인하는 용도로 이 인덱스를 사용하세요.\"\n",
    "    )\n",
    "    node = IndexNode(text=doc_summary, index_id=title)\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "qg6MfspJa803"
   },
   "outputs": [],
   "source": [
    "# 에이전트 선택 인덱스(노드) 정의\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=1)\n",
    "\n",
    "# 에이전트 자체를 쿼리엔진으로 하여 선택된 에이전트가 쿼리 엔진 역할을 하도록 구성\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever},\n",
    "    query_engine_dict=agents,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    recursive_retriever,\n",
    "    response_synthesizer=response_synthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "gevDJasWZDm_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: 셀빅에 대해 알려줘\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 셀빅\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 셀빅: 셀빅에 대해 알려줘\n",
      "\u001b[0mAdded user message to memory: 셀빅에 대해 알려줘\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"input\":\"셀빅\"}\n",
      "Got output: CellVic was a type of PDA produced in South Korea by jTel, later acquired by Kolon and renamed Cellvic. It was significant as the first PDA operating system developed in Korea, tailored to the local environment. jTel focused on securing applications through regular competitions and support for individual developers, resulting in a variety of applications. The device lineup ranged from the lightweight CellVic i to the advanced smartphone mycube. However, after Kolon took over, the company ceased further support due to competition in the smartphone market with PocketPC devices, leading to discontinuation in 2004.\n",
      "========================\n",
      "\n",
      "\u001b[1;3;32mGot response: 셀빅(CellVic)은 대한민국에서 jTel에 의해 생산된 PDA 유형이었으며, 나중에 Kolon에 인수되어 Cellvic으로 이름이 바뀌었습니다. 셀빅은 한국에서 개발된 첫 PDA 운영 체제로, 현지 환경에 맞춰 설계되었다는 점에서 중요합니다. jTel은 정기적인 경쟁과 개인 개발자에 대한 지원을 통해 애플리케이션을 확보하는 데 중점을 두었고, 이로 인해 다양한 애플리케이션이 생겨났습니다. 제품 라인업은 가벼운 CellVic i부터 고급 스마트폰 mycube에 이르기까지 다양했습니다. 그러나 Kolon이 인수한 후, PocketPC 장치와의 스마트폰 시장 경쟁으로 인해 추가 지원을 중단하고 2004년에 단종되었습니다.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 해당 문서에서만 답변 가능한 굉장히 구체적인 질문 테스트\n",
    "response = query_engine.query(\"셀빅에 대해 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7fUHfWDTk2Z"
   },
   "source": [
    "- Decoupling 전략은 모든 RAG에 필수적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNetkg4y4yupAy1wYJjqHLM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
