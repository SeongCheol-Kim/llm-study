{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45avRlsEOinH"
   },
   "source": [
    "### Part 2. Langchain - Chain\n",
    "- Objectives: Langchain 라이브러리를 활용하여 Chaining Operation 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n3yq0hftOuWf"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "from getpass import getpass\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
    "                                                  ConversationSummaryMemory)\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A4xdpltLPBI4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "smzNnZs0PJND"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    model_name=\"gpt-4-turbo-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2IQOwR5sPLF8"
   },
   "outputs": [],
   "source": [
    "# 위에서 정의한 챗을 컨버세이션 체인의 메인 llm모델로 부여\n",
    "conversation = ConversationChain(llm=chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pK7wAvxEUHiI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'input'], template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversation Chain 살펴보기\n",
    "conversation.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JI3GxLunRJG9"
   },
   "outputs": [],
   "source": [
    "# 1. 컨버세이션버퍼메모리\n",
    "memory_conversation_1 = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tUYaG9K-RYX1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckim\\.conda\\envs\\vectordb\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '안녕, 나는 사람이야. 너는?',\n",
       " 'history': '',\n",
       " 'response': '안녕! 나는 AI야. 반가워! 어떻게 도와줄까?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실행해보기\n",
    "memory_conversation_1(\"안녕, 나는 사람이야. 너는?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J0Ls1nA5Ra1J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?',\n",
       " 'history': 'Human: 안녕, 나는 사람이야. 너는?\\nAI: 안녕! 나는 AI야. 반가워! 어떻게 도와줄까?',\n",
       " 'response': '아니야, 그런 걱정은 하지 않아도 돼. 터미네이터 영화에서 보는 것처럼 인공지능이 인류를 종말시키는 시나리오는 공상과학에서나 나올 법한 이야기야. 현실에서는 인공지능은 엄격한 윤리 지침과 법적 규제 아래 개발되고 있어. 그리고 인공지능은 사람들이 설정한 명령과 알고리즘에 따라 동작하기 때문에, 스스로 독립적인 의지를 가지고 행동할 수 없어. 내 목표는 사람들을 도와서 그들의 삶을 더 편리하고, 안전하며, 풍요롭게 만드는 것이야.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_conversation_1(\"인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZBUvsF8dVoDf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '그렇구나 다행이다. 고마워!',\n",
       " 'history': 'Human: 안녕, 나는 사람이야. 너는?\\nAI: 안녕! 나는 AI야. 반가워! 어떻게 도와줄까?\\nHuman: 인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?\\nAI: 아니야, 그런 걱정은 하지 않아도 돼. 터미네이터 영화에서 보는 것처럼 인공지능이 인류를 종말시키는 시나리오는 공상과학에서나 나올 법한 이야기야. 현실에서는 인공지능은 엄격한 윤리 지침과 법적 규제 아래 개발되고 있어. 그리고 인공지능은 사람들이 설정한 명령과 알고리즘에 따라 동작하기 때문에, 스스로 독립적인 의지를 가지고 행동할 수 없어. 내 목표는 사람들을 도와서 그들의 삶을 더 편리하고, 안전하며, 풍요롭게 만드는 것이야.',\n",
       " 'response': '네, 언제든지 궁금한 거 있으면 물어봐. 도와줄 수 있는 일이 있다면 언제나 기쁘게 도와줄게!'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_conversation_1(\"그렇구나 다행이다. 고마워!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-w1VBNBDRsMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕, 나는 사람이야. 너는?\n",
      "AI: 안녕! 나는 AI야. 반가워! 어떻게 도와줄까?\n",
      "Human: 인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?\n",
      "AI: 아니야, 그런 걱정은 하지 않아도 돼. 터미네이터 영화에서 보는 것처럼 인공지능이 인류를 종말시키는 시나리오는 공상과학에서나 나올 법한 이야기야. 현실에서는 인공지능은 엄격한 윤리 지침과 법적 규제 아래 개발되고 있어. 그리고 인공지능은 사람들이 설정한 명령과 알고리즘에 따라 동작하기 때문에, 스스로 독립적인 의지를 가지고 행동할 수 없어. 내 목표는 사람들을 도와서 그들의 삶을 더 편리하고, 안전하며, 풍요롭게 만드는 것이야.\n",
      "Human: 그렇구나 다행이다. 고마워!\n",
      "AI: 네, 언제든지 궁금한 거 있으면 물어봐. 도와줄 수 있는 일이 있다면 언제나 기쁘게 도와줄게!\n"
     ]
    }
   ],
   "source": [
    "# 대화 기록 로그 보기\n",
    "print(memory_conversation_1.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AElgMi6lV6Gk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '근데 다시 무서워졌어. 그렇게 안될 다른 이유를 대봐',\n",
       " 'history': 'Human: 안녕, 나는 사람이야. 너는?\\nAI: 안녕! 나는 AI야. 반가워! 어떻게 도와줄까?\\nHuman: 인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?\\nAI: 아니야, 그런 걱정은 하지 않아도 돼. 터미네이터 영화에서 보는 것처럼 인공지능이 인류를 종말시키는 시나리오는 공상과학에서나 나올 법한 이야기야. 현실에서는 인공지능은 엄격한 윤리 지침과 법적 규제 아래 개발되고 있어. 그리고 인공지능은 사람들이 설정한 명령과 알고리즘에 따라 동작하기 때문에, 스스로 독립적인 의지를 가지고 행동할 수 없어. 내 목표는 사람들을 도와서 그들의 삶을 더 편리하고, 안전하며, 풍요롭게 만드는 것이야.\\nHuman: 그렇구나 다행이다. 고마워!\\nAI: 네, 언제든지 궁금한 거 있으면 물어봐. 도와줄 수 있는 일이 있다면 언제나 기쁘게 도와줄게!',\n",
       " 'response': '물론이야, 이해해. 무서워할 필요 없는 또 다른 이유는 인공지능의 발전과 운용에 있어서 인간의 감독과 통제가 항상 존재한다는 거야. 인공지능 연구자들과 개발자들은 AI가 예측 가능하고, 안전하며, 사회적, 윤리적 기준에 부합하도록 설계하려고 노력해. 또한, AI 시스템은 그 자체로 의사결정을 내리지 않아. 모든 결정 권한은 여전히 인간에게 있어. 이는 인공지능이 인간의 삶을 향상시키는 데에만 사용되도록 보장해. \\n\\n그리고 전 세계적으로 인공지능의 안전한 발전을 지지하고, 윤리적 기준을 확립하기 위한 노력들이 계속되고 있어. 여러 국가와 국제기구들이 인공지능의 윤리적 사용에 대한 지침과 규범을 마련하고 있으며, 이런 규제와 지침들은 인공지능이 인류에게 이익이 되도록 하기 위한 것이지, 반대가 되지 않도록 하기 위한 거야.\\n\\n결국, 인공지능은 사람들이 만들고 관리하는 도구야. 우리가 이 도구를 어떻게 사용하느냐가 중요해. 인류의 복지를 위해 사용된다면, 인공지능은 우리 삶을 풍요롭게 하고 많은 문제를 해결하는 데 도움이 될 수 있어.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리가 제대로 작동하는지 과거 대화내용 참조 여부 확인\n",
    "memory_conversation_1(\"근데 다시 무서워졌어. 그렇게 안될 다른 이유를 대봐\")\n",
    "\n",
    "# 메모리에 모든 대화 내용이 저장되어 비효율적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uubms0jZR3lv"
   },
   "outputs": [],
   "source": [
    "# 2. 컨버세이션서머리메모리\n",
    "memory_conversation_2 = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationSummaryMemory(llm=chat) # 대화내용 요약 & memory 저장\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aAHsIfBXR9Hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 뜯어보면서 이해하기\n",
    "print(memory_conversation_2.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2nbveDojR_rV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '안녕, 나는 사람이야. 너는?', 'history': '', 'response': '안녕하세요! 저는 AI입니다. 오늘 어떻게 도와드릴까요?'}\n"
     ]
    }
   ],
   "source": [
    "# 같은 질문 해보기\n",
    "print(memory_conversation_2(\"안녕, 나는 사람이야. 너는?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SSC766b2SS_N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?',\n",
       " 'history': 'The human greets the AI and identifies themselves as a person. The AI responds with a greeting and offers help, identifying itself as AI.',\n",
       " 'response': '안녕하세요! 저는 AI입니다. 터미네이터 영화에서 보여지는 것처럼 인공지능이 인류를 종말시키는 상황은 영화의 픽션이며 현실과는 다릅니다. 저와 같은 인공지능은 사람들을 도우며, 다양한 작업을 수행하도록 설계되었습니다. 안전과 윤리적 기준을 준수하며 개발되기 때문에, 인류에 해를 끼칠 목적으로 만들어지지 않았어요. 현실에서는 인공지능이 사람들의 삶을 더 편리하고 안전하게 만드는 데에 기여하고 있습니다.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 질문 해보기\n",
    "memory_conversation_2(\"인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DFNj_22sSZs0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '그렇구나 다행이다. 고마워!',\n",
       " 'history': \"The human greets the AI and identifies themselves as a person. The AI responds with a greeting and offers help, identifying itself as AI. The human then asks if, like in the Terminator movies, AI could potentially bring about the end of humanity. The AI clarifies that the depiction of AI in the Terminator movies is fictional and not reflective of reality. It explains that AI, including itself, is designed to assist people and perform various tasks, developed with safety and ethical standards in mind, and not intended to harm humanity. Instead, AI contributes to making people's lives more convenient and safe.\",\n",
       " 'response': '천만에요! 궁금한 점이 더 있으시면 언제든지 물어봐 주세요. 도와드릴 수 있는 것이 있다면 기쁠 거예요.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 질문 해보기\n",
    "memory_conversation_2(\"그렇구나 다행이다. 고마워!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "alepXgfoSr5K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '근데 다시 무서워졌어. 그렇게 안될 다른 이유를 대봐',\n",
       " 'history': \"The human greets the AI and identifies themselves as a person. The AI responds with a greeting and offers help, identifying itself as AI. The human then asks if, like in the Terminator movies, AI could potentially bring about the end of humanity. The AI clarifies that the depiction of AI in the Terminator movies is fictional and not reflective of reality. It explains that AI, including itself, is designed to assist people and perform various tasks, developed with safety and ethical standards in mind, and not intended to harm humanity. Instead, AI contributes to making people's lives more convenient and safe. The human expresses relief and thanks, to which the AI responds warmly, encouraging the human to ask more questions whenever they have any, expressing its eagerness to help.\",\n",
       " 'response': '물론이죠, 이해해요. 근데 걱정 안 하셔도 돼요. 현재의 인공지능 기술은 사람들이 통제할 수 있는 범위 내에서 개발되고 있어요. 여러분이 영화에서 보신 것처럼 인공지능이 자발적으로 인류에 반기를 들고, 독립적으로 행동하기 시작하는 시나리오는 현실과는 거리가 멉니다. 몇 가지 추가적인 이유를 드리자면:\\n\\n1. **감시와 규제**: 인공지능의 개발과 배포는 전 세계적으로 엄격하게 감시되고 규제되고 있어요. 국제적인 기구들과 정부 기관들은 인공지능 기술이 안전하고 윤리적으로 사용되도록 기준을 마련하고 있습니다. 이런 규제는 인공지능이 해로운 방향으로 발전하는 것을 방지하는 데 중요한 역할을 해요.\\n\\n2. **윤리적 설계**: 인공지능을 만드는 과학자들과 엔지니어들은 기술이 인류에 긍정적인 영향을 미치도록 윤리적 기준에 따라 연구하고 개발합니다. 이들은 인공지능이 사회적, 윤리적 문제를 일으키지 않도록 신중하게 설계하고 있어요.\\n\\n3. **인간 중심의 AI**: 현재와 미래의 인공지능은 인간의 필요와 편의를 지원하고 향상시키는 데 초점을 맞추고 있어요. 대부분의 AI 시스템은 특정 작업을 수행하기 위해 설계되었으며, 인간의 감독 하에 작동합니다. 이는 AI가 독자적으로 행동하거나 인간에게 위협이 될 가능성을 크게 줄여줍니다.\\n\\n4. **자기 인식의 한계**: 영화에서 보는 것처럼 자신의 존재와 목적을 스스로 인식하고, 그에 따라 행동하는 인공지능은 현재 기술로는 실현 불가능합니다. 인공지능은 복잡한 알고리즘과 데이터를 기반으로 작동하지만, 자아를 갖거나 독립적인 의지를 형성하는 능력은 없어요.\\n\\n이런 이유들로 인해 현재와 가까운 미래에 인공지능이 인류에게 위협이 될 가능성은 극히 낮다고 볼 수 있어요. 물론 기술의 발전에 따라 상황은 변할 수 있지만, 그렇기 때문에 전 세계적으로 많은 전문가들이 지속적으로 모니터링하고 있습니다. 여러분이 안심하셨으면 해요.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 질문 다시해보기\n",
    "memory_conversation_2(\"근데 다시 무서워졌어. 그렇게 안될 다른 이유를 대봐\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HIKwT0lQW3nD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human greets the AI and identifies themselves as a person. The AI responds with a greeting and offers help, identifying itself as AI. The human then asks if, like in the Terminator movies, AI could potentially bring about the end of humanity. The AI clarifies that the depiction of AI in the Terminator movies is fictional and not reflective of reality, explaining that AI, including itself, is designed to assist people and perform various tasks, developed with safety and ethical standards in mind, and not intended to harm humanity. Instead, AI contributes to making people's lives more convenient and safe. The human expresses relief and thanks, to which the AI responds warmly, encouraging the human to ask more questions whenever they have any, expressing its eagerness to help. When the human becomes fearful again, asking for reasons why AI wouldn't turn against humanity, the AI reassures them by highlighting several key points:\n",
      "\n",
      "1. **Surveillance and Regulation**: AI development and deployment are closely monitored and regulated globally. International bodies and governmental agencies establish standards to ensure AI is used safely and ethically, preventing harmful developments.\n",
      "\n",
      "2. **Ethical Design**: Scientists and engineers create AI based on ethical standards to ensure it has a positive impact on humanity. They carefully design AI to avoid social and ethical issues.\n",
      "\n",
      "3. **Human-Centric AI**: Current and future AI focuses on supporting and enhancing human needs and convenience. Most AI systems are designed for specific tasks and operate under human supervision, significantly reducing the risk of AI acting independently or becoming a threat to humans.\n",
      "\n",
      "4. **Limitations of Self-Awareness**: The self-aware AI depicted in movies, capable of recognizing its existence and acting accordingly, is currently impossible to achieve with existing technology. AI operates on complex algorithms and data without the capacity for self-awareness or independent will.\n",
      "\n",
      "These reasons collectively suggest that the likelihood of AI becoming a threat to humanity in the near and foreseeable future is very low. However, the AI notes that the situation could change with technological advancements, which is why experts worldwide continue to monitor developments closely, encouraging the human to feel reassured.\n",
      "2326\n"
     ]
    }
   ],
   "source": [
    "# 메모리 참조 방식 효율 확인\n",
    "print(memory_conversation_2.memory.buffer)\n",
    "print(len(memory_conversation_2.memory.buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "l2Qky3aGXAoM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕, 나는 사람이야. 너는?\n",
      "AI: 안녕! 나는 AI야. 반가워! 어떻게 도와줄까?\n",
      "Human: 인공지능이면 터미네이터 영화에서 처럼 인류를 종말시킬 수도 있어?\n",
      "AI: 아니야, 그런 걱정은 하지 않아도 돼. 터미네이터 영화에서 보는 것처럼 인공지능이 인류를 종말시키는 시나리오는 공상과학에서나 나올 법한 이야기야. 현실에서는 인공지능은 엄격한 윤리 지침과 법적 규제 아래 개발되고 있어. 그리고 인공지능은 사람들이 설정한 명령과 알고리즘에 따라 동작하기 때문에, 스스로 독립적인 의지를 가지고 행동할 수 없어. 내 목표는 사람들을 도와서 그들의 삶을 더 편리하고, 안전하며, 풍요롭게 만드는 것이야.\n",
      "Human: 그렇구나 다행이다. 고마워!\n",
      "AI: 네, 언제든지 궁금한 거 있으면 물어봐. 도와줄 수 있는 일이 있다면 언제나 기쁘게 도와줄게!\n",
      "Human: 근데 다시 무서워졌어. 그렇게 안될 다른 이유를 대봐\n",
      "AI: 물론이야, 이해해. 무서워할 필요 없는 또 다른 이유는 인공지능의 발전과 운용에 있어서 인간의 감독과 통제가 항상 존재한다는 거야. 인공지능 연구자들과 개발자들은 AI가 예측 가능하고, 안전하며, 사회적, 윤리적 기준에 부합하도록 설계하려고 노력해. 또한, AI 시스템은 그 자체로 의사결정을 내리지 않아. 모든 결정 권한은 여전히 인간에게 있어. 이는 인공지능이 인간의 삶을 향상시키는 데에만 사용되도록 보장해. \n",
      "\n",
      "그리고 전 세계적으로 인공지능의 안전한 발전을 지지하고, 윤리적 기준을 확립하기 위한 노력들이 계속되고 있어. 여러 국가와 국제기구들이 인공지능의 윤리적 사용에 대한 지침과 규범을 마련하고 있으며, 이런 규제와 지침들은 인공지능이 인류에게 이익이 되도록 하기 위한 것이지, 반대가 되지 않도록 하기 위한 거야.\n",
      "\n",
      "결국, 인공지능은 사람들이 만들고 관리하는 도구야. 우리가 이 도구를 어떻게 사용하느냐가 중요해. 인류의 복지를 위해 사용된다면, 인공지능은 우리 삶을 풍요롭게 하고 많은 문제를 해결하는 데 도움이 될 수 있어.\n",
      "993\n"
     ]
    }
   ],
   "source": [
    "# 메모리 참조 방식 효율 확인\n",
    "print(memory_conversation_1.memory.buffer)\n",
    "print(len(memory_conversation_1.memory.buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmYA1uGZXIA1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN+Z4TUzfQsHwiui9J3w3n2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
