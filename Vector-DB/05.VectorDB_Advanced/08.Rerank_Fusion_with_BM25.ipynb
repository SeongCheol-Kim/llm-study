{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Zqkl4sDzAuv7"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EfaNsqnpA6uS"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "# llama2 pdf download: https://arxiv.org/pdf/2307.09288.pdf\n",
    "documents = loader.load(file_path=\"../data/llama2.pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e4FIwfIBzK-c"
   },
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9ycT_Cb6BGzc"
   },
   "outputs": [],
   "source": [
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dU-hwMgJA-Ff"
   },
   "outputs": [],
   "source": [
    "# 청킹 전략 정의\n",
    "splitter = SentenceSplitter(chunk_size=256)\n",
    "index = VectorStoreIndex.from_documents(documents, transformations=[splitter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F17CulzDA_ym"
   },
   "outputs": [],
   "source": [
    "# # 기반 모델 정의\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "onkT0aRe7OKf"
   },
   "outputs": [],
   "source": [
    "# Semantic Search Retriever 정의\n",
    "vector_retriever = index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "# BM25 Sparse Search Retriever 정의\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    docstore=index.docstore, similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tzGBepdY84li"
   },
   "outputs": [],
   "source": [
    "# 각각의 Retrieval 결과\n",
    "bm_result = bm25_retriever.retrieve('Tell me what llama2 and gpt are, and provide key differences between them. provide it with bullet points for better readability')\n",
    "vector_result = vector_retriever.retrieve('Tell me what llama2 and gpt are, and provide key differences between them. provide it with bullet points for better readability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IEGKDOTy81at"
   },
   "outputs": [],
   "source": [
    "# # BM25 Retrieval 결과\n",
    "# for node in bm_result:\n",
    "#     print(f\"Score: {node.score:.2f} - {node.text}...\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7zDjZFuZ9mW6"
   },
   "outputs": [],
   "source": [
    "# # Semantic Retrieval 결과\n",
    "# for node in vector_result:\n",
    "#     print(f\"Score: {node.score:.2f} - {node.text}...\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7E_o6MNl7ODD"
   },
   "outputs": [],
   "source": [
    "# Hybrid Search용 query fusion retrieval 정의\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=2,\n",
    "    num_queries=4,\n",
    "    mode=\"reciprocal_rerank\",\n",
    "    use_async=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Sgf6M-NT7N6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated queries:\n",
      "1. What is llama2 and how does it differ from gpt?\n",
      "2. Compare and contrast llama2 and gpt in terms of functionality and features.\n",
      "3. Key differences between llama2 and gpt - a detailed comparison.\n"
     ]
    }
   ],
   "source": [
    "# Query Generation + generated query별 hybrid retrieval 진행\n",
    "nodes_with_scores = retriever.retrieve('Tell me what llama2 and gpt are, and provide key differences between them. provide it with bullet points for better readability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7x2XSp4p7ikK"
   },
   "outputs": [],
   "source": [
    "# # 최종 Hybrid Search Retrieval 결과\n",
    "# for node in nodes_with_scores:\n",
    "#     print(f\"Score: {node.score:.2f} - {node.text}...\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "42ugDAI78uQt"
   },
   "outputs": [],
   "source": [
    "# Retrieval 모듈에 쿼리엔진(Augmented Generator) 더하기\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever) # 하이브리드 쿼리엔진\n",
    "query_engine_0 = RetrieverQueryEngine.from_args(bm25_retriever) # BM25 쿼리엔진\n",
    "query_engine_1 = RetrieverQueryEngine.from_args(vector_retriever) # 시멘틱 쿼리엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CdKWS6--PLj"
   },
   "outputs": [],
   "source": [
    "response_0 = query_engine_0.query('Tell me what llama2 and gpt are, and provide key differences between them. provide it with bullet points for better readability.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CdKWS6--PLj"
   },
   "outputs": [],
   "source": [
    "response_1 = query_engine_1.query('Tell me what llama2 and gpt are, and provide key differences between them. provide it with bullet points for better readability.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMJ-4eeh9zFx"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query('Tell me what llama2 and gpt are, and provide key differences between them.provide it with bullet points for better readability.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BlO8MlB-YYg"
   },
   "outputs": [],
   "source": [
    "# BM25 쿼리결과\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(response_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIPKeM05-ciJ"
   },
   "outputs": [],
   "source": [
    "# Semantic 쿼리결과\n",
    "display_response(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N11FtAQg912C"
   },
   "outputs": [],
   "source": [
    "# Hybrid(rerank 적용) 쿼리결과\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJDkqTqODEMO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOdGQ72tfvFE0dVNWvJEeQx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
